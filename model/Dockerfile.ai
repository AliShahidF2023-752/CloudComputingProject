# Use Python 3.10 slim as base
FROM python:3.10-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first to leverage cache
COPY requirements.txt .

# Install dependencies (including CPU version of PyTorch to save space/memory)
# We specifically target the lines relevant to AI service to avoid installing heavyweight browser stuff if possible,
# but using the single requirements.txt is easier for maintenance. 
# pip will install everything, which is fine, usually around 1-2GB total.
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code and model files
COPY run.py .
COPY utils.py .
COPY config.json .
COPY tokenizer.json .
COPY tokenizer_config.json .
COPY vocab.json .
COPY merges.txt .
COPY special_tokens_map.json .

# Copy model weights - these might be large
# Docker context sending might take a while if these are huge.
COPY pytorch_model.bin .
COPY model.safetensors .

# Expose port
EXPOSE 1234

# Command to run the application
CMD ["uvicorn", "run:app", "--host", "0.0.0.0", "--port", "1234"]
